
GenerateArguments:
  #model_path: signllava/checkpoints/how2sign_llama3_8b_nocontext_pose_pretrain/
  #model_path: signllava/checkpoints/pretrain_how2sign
  #model_path: signllava/checkpoints/llama3_8b_pre_20ep_mae_dino_pose_YTasl_par_keyword1
  model_path: signllava/checkpoints/llama3_8b_pre_400ep_mae_dino_sign2vec
  checkpoint_num: 3950
  num_datapoints: 100 # -1 for all
  #task: translation # translation, one_word_present, multi_word_present, is_reversed
  generation_des: generation_prefix_no_translation.json
  #generate_des: generation.nocontext.json
  #generate_des: generation.prepared_predicted_context.json
  #generate_des: generation.on_the_fly_predicted_context.json
  model_base: meta-llama/Meta-Llama-3-8B-Instruct
  conv_mode: llava_sign_llama_3
  top_p: 1
  min_length: 1 
  temperature: 0.1
  do_sample: False # otherwise use greedy decoding
  skip_special_tokens: True
  num_beams: 5
  remove_invalid_values: True
  max_new_tokens: 200
  do_verbose: True
  seed: 42
  bf16: True
LoraArguments:
  bits: 16 # 4, 8 to enable quantization
  quant_type: nf4
  double_quant: True # Compress the quantization statistics through double quantization.
  lora_enable: False
  lora_r: 64
  lora_alpha: 16
  lora_dropout: 0.05
  lora_weight_path: ""
  lora_bias: "none"
SignDataArguments:
  prepared_predicted_context: False 
  on_the_fly_predicted_context: False
  context_window_size: 0 #number of preceding sentences
  prelude_window_size: 0 #number of sentences at the beginning of the discourse 
  data_dir: /export/fs06/xzhan138/Sign_LLaVA/signllava/data/How2Sign/
  annotation_path: /export/fs06/xzhan138/Sign_LLaVA/signllava/data/How2Sign/annotation.train.json
  #annotation_path: /export/fs06/xzhan138/Sign_LLaVA/signllava/checkpoints/pretrain_how2sign/generation.nocontext.json
  visual_features:
    sign2vec:
      enable_input: True
      test: sign2vec/metadata_sign2vec.train.json
    mae:
      enable_input: True
      test: mae/metadata_mae.train.json
    dino:
      enable_input: True
      test: dino/metadata_dino.train.json
    pose:
      enable_input: False
      test: pose/metadata_pose.train.json
SignModelArguments:
  projectors:
    sign2vec: 
      dim: 768
      projector_type: mlp2x_gelu
    mae: 
      dim: 768
      projector_type: mlp2x_gelu
    dino: 
      dim: 1152
      projector_type: mlp2x_gelu
    pose: 
      dim: 208
      projector_type: mlp2x_gelu
